{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c91f19-9c2a-4eb5-8f21-284c5be4ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/soCzech/TransNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8c909-de87-447d-8fd6-e179d3aca816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e4b5b-dd8b-4ad4-bbd5-75c852663922",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d50924-0f4f-45f3-8772-74755328b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a61777-3faa-4b1d-b0dc-b4d5d33b3056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/AIC/TransNet\n"
     ]
    }
   ],
   "source": [
    "%cd TransNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86958bb2-1369-4ccb-8c08-2ce529f7a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhentu/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhentu/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhentu/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhentu/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhentu/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhentu/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from transnet import TransNetParams, TransNet\n",
    "from transnet_utils import draw_video_with_predictions, scenes_from_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251ed7ed-ba7d-46de-b68d-3565af7f93bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'ndims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-478ac1d866df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Call conv3d with data1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-478ac1d866df>\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(inp, filters, dilation_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Conv3D_{:d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a NumPy array for data1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.12/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m           \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m           spec.max_ndim is not None):\n\u001b[0;32m-> 1463\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1464\u001b[0m           raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[1;32m   1465\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'ndims'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def conv3d(inp, filters, dilation_rate):\n",
    "    return tf.keras.layers.Conv3D(filters, kernel_size=3, dilation_rate=(dilation_rate, 1, 1), padding=\"SAME\", activation=tf.nn.relu, use_bias=True, name=\"Conv3D_{:d}\".format(dilation_rate))(inp)\n",
    "\n",
    "# Create a NumPy array for data1\n",
    "data1 = np.ones((1, 27, 48, 3))  # Adjust the shape according to your needs\n",
    "\n",
    "# Add a batch dimension if necessary\n",
    "data1 = np.expand_dims(data1, axis=0)  # Shape should now be (1, 27, 48, 3)\n",
    "\n",
    "# Call conv3d with data1\n",
    "x2 = conv3d(data1, 16, 4)\n",
    "print(x2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f4bd23-4fcd-442c-b194-e4b087a765b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = TransNetParams()\n",
    "params.CHECKPOINT_PATH = \"./model/transnet_model-F16_L3_S2_D256\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7196790d-1b5d-472b-adfc-b7274338a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNet] Creating ops.\n",
      "           Input (?, ?, 27, 48, 3)\n",
      "           SDDCNN_1\n",
      "           > DDCNN_1 (?, ?, 27, 48, 64)\n",
      "           > DDCNN_2 (?, ?, 27, 48, 64)\n",
      "           MaxPool (?, ?, 13, 24, 64)\n",
      "           SDDCNN_2\n",
      "           > DDCNN_1 (?, ?, 13, 24, 128)\n",
      "           > DDCNN_2 (?, ?, 13, 24, 128)\n",
      "           MaxPool (?, ?, 6, 12, 128)\n",
      "           SDDCNN_3\n",
      "           > DDCNN_1 (?, ?, 6, 12, 256)\n",
      "           > DDCNN_2 (?, ?, 6, 12, 256)\n",
      "           MaxPool (?, ?, 3, 6, 256)\n",
      "           Flatten (?, ?, 4608)\n",
      "           Dense (?, ?, 256)\n",
      "           Logits (?, ?, 2)\n",
      "           Predictions (?, ?)\n",
      "[TransNet] Network built.\n",
      "[TransNet] Found 4614850 trainable parameters.\n",
      "INFO:tensorflow:Restoring parameters from ./model/transnet_model-F16_L3_S2_D256\n",
      "[TransNet] Parameters restored from 'transnet_model-F16_L3_S2_D256'.\n"
     ]
    }
   ],
   "source": [
    "net = TransNet(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7463222a-9867-49db-81d7-9c3ecbf4a3ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "video_path = \"/mnt/f/AIC/Video/Thời sự toàn cảnh tối 9-7-Nhậu hết rượu, lấy cồn rửa tay ra uống, 4 người nhập viện  VTV24.mp4\"\n",
    "video_stream, err = (\n",
    "    ffmpeg\n",
    "    .input(video_path)\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(params.INPUT_WIDTH, params.INPUT_HEIGHT))\n",
    "    .run(capture_stdout=True)\n",
    ")\n",
    "video = np.frombuffer(video_stream, np.uint8).reshape([-1, params.INPUT_HEIGHT, params.INPUT_WIDTH, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c00539c-6c96-4d11-a011-581aff1cbb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57629, 27, 48, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6b0e9-1fc3-4766-8b33-2db5d9cc074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNet] Processing video frames 26150/57629"
     ]
    }
   ],
   "source": [
    "predictions = net.predict_video(video)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_video_with_predictions(video, predictions, threshold=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d163012",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = scenes_from_predictions(predictions, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming scenes is your array\n",
    "# Remove the truncation for display\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Display the array\n",
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb114c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
